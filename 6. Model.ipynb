{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5f328f0",
   "metadata": {},
   "source": [
    "Now it is time to make the model for to predict housing prices based off all the data we have gathered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a7fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Configure Notebook\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_context(\"notebook\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b042706a",
   "metadata": {},
   "source": [
    "Lets read the test and train csvs and store them in their respective variables.  As you can see, the data has all the features we have developed, but no date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a230e988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>Price</th>\n",
       "      <th>propertyLng</th>\n",
       "      <th>propertyLat</th>\n",
       "      <th>T_Detached</th>\n",
       "      <th>T_Semi-Detached</th>\n",
       "      <th>T_other</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>within_learning centre</th>\n",
       "      <th>#_of_learning centre_within</th>\n",
       "      <th>within_university</th>\n",
       "      <th>#_of_university_within</th>\n",
       "      <th>within_subway_station</th>\n",
       "      <th>#_of_subway_station_within</th>\n",
       "      <th>within_cemetery</th>\n",
       "      <th>#_of_cemetery_within</th>\n",
       "      <th>within_green_space</th>\n",
       "      <th>#_of_green_space_within</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15-fifth-street</td>\n",
       "      <td>711924.0</td>\n",
       "      <td>-79.5013</td>\n",
       "      <td>43.597</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15-fifth-street</td>\n",
       "      <td>711924.0</td>\n",
       "      <td>-79.5013</td>\n",
       "      <td>43.597</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-fifth-street</td>\n",
       "      <td>711924.0</td>\n",
       "      <td>-79.5013</td>\n",
       "      <td>43.597</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15-fifth-street</td>\n",
       "      <td>711924.0</td>\n",
       "      <td>-79.5013</td>\n",
       "      <td>43.597</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15-fifth-street</td>\n",
       "      <td>711924.0</td>\n",
       "      <td>-79.5013</td>\n",
       "      <td>43.597</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           address     Price  propertyLng  propertyLat  T_Detached  \\\n",
       "0  15-fifth-street  711924.0     -79.5013       43.597           1   \n",
       "1  15-fifth-street  711924.0     -79.5013       43.597           1   \n",
       "2  15-fifth-street  711924.0     -79.5013       43.597           1   \n",
       "3  15-fifth-street  711924.0     -79.5013       43.597           1   \n",
       "4  15-fifth-street  711924.0     -79.5013       43.597           1   \n",
       "\n",
       "   T_Semi-Detached  T_other  Utilities  Rooms  Bathrooms  ...  \\\n",
       "0                0        0        2.5    6.5        2.0  ...   \n",
       "1                0        0        2.5    6.5        2.0  ...   \n",
       "2                0        0        2.5    6.5        2.0  ...   \n",
       "3                0        0        2.5    6.5        2.0  ...   \n",
       "4                0        0        2.5    6.5        2.0  ...   \n",
       "\n",
       "   within_learning centre  #_of_learning centre_within  within_university  \\\n",
       "0                     0.0                          0.0                0.0   \n",
       "1                     0.0                          0.0                0.0   \n",
       "2                     0.0                          0.0                0.0   \n",
       "3                     0.0                          0.0                0.0   \n",
       "4                     0.0                          0.0                0.0   \n",
       "\n",
       "   #_of_university_within  within_subway_station  #_of_subway_station_within  \\\n",
       "0                     0.0                    0.0                         0.0   \n",
       "1                     0.0                    0.0                         0.0   \n",
       "2                     0.0                    0.0                         0.0   \n",
       "3                     0.0                    0.0                         0.0   \n",
       "4                     0.0                    0.0                         0.0   \n",
       "\n",
       "   within_cemetery  #_of_cemetery_within  within_green_space  \\\n",
       "0              0.0                   0.0                 1.0   \n",
       "1              0.0                   0.0                 1.0   \n",
       "2              0.0                   0.0                 1.0   \n",
       "3              0.0                   0.0                 1.0   \n",
       "4              0.0                   0.0                 1.0   \n",
       "\n",
       "   #_of_green_space_within  \n",
       "0                      8.0  \n",
       "1                      8.0  \n",
       "2                      8.0  \n",
       "3                      8.0  \n",
       "4                      8.0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv') # import training data\n",
    "test = pd.read_csv('test.csv') # import testing data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb512663",
   "metadata": {},
   "source": [
    "As we saw in our analysis, there are some outliers which will throw off our regression model, lets develop a function to filter these out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b132d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    data = data[data['Size'] < 1000] # filter out size greater than 1000\n",
    "    data = data[data['Rooms'] > 0] # filter out rooms = 0\n",
    "    data = data[data['Bedrooms'] > 0] # filter out bedrooms = 0\n",
    "    data = data[(data['Price'] / data['Cuml Inflation']) <= 3000000] # filter out price > 3,000,000\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0035374c",
   "metadata": {},
   "source": [
    "Lets also come up with a function to select the features we want to use. This is based off the analysis we did (for instance the fronting direction had no impact), but is also including as many features as possible so we can compare how our model does with and without certain features. Lets make a couple of these so we can compare how different feature perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89b1a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All features for our final model\n",
    "def feature_engineering(data):\n",
    "\n",
    "    feature_selected = ['Size', 'T_Detached', 'T_Semi-Detached', 'T_other', 'Utilities', 'Rooms', 'Bathrooms',\n",
    "                       'Kitchens', 'Bedrooms', 'Parking', 'Fireplace', 'Feature', 'Pool', 'Interest %', 'Delta',\n",
    "                       'Population', 'crime_density_per_cap', 'crime_density', 'Neighb_pop', 'Raw Inflation',\n",
    "                       'Education investment in area', 'Transportation investment in area', 'Unemployment',\n",
    "                        'Colleges/Universities investment in area', 'propertyLng', 'propertyLat',\n",
    "                       'within_academy', '#_of_academy_within', 'within_education_centres', \n",
    "                        '#_of_education_centres_within', 'within_highschool', '#_of_highschool_within',\n",
    "                        'within_elementary school', '#_of_elementary school_within', 'within_college',\n",
    "                        '#_of_college_within', 'within_learning centre', '#_of_learning centre_within',\n",
    "                        'within_university', '#_of_university_within', 'within_subway_station',\n",
    "                        '#_of_subway_station_within', 'within_cemetery', '#_of_cemetery_within', 'within_green_space'\n",
    "                        , '#_of_green_space_within']\n",
    "    \n",
    "    return data[feature_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "293d46f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the features from the housing database\n",
    "def feature_houses(data):\n",
    "\n",
    "    feature_selected = ['Size', 'T_Detached', 'T_Semi-Detached', 'T_other', 'Utilities', 'Rooms', 'Bathrooms',\n",
    "                       'Kitchens', 'Bedrooms', 'Parking', 'Fireplace', 'Feature', 'Pool']\n",
    "    \n",
    "    return data[feature_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c05d6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the features from the housing database with financial features\n",
    "def feature_financial(data):\n",
    "\n",
    "    feature_selected = ['Size', 'T_Detached', 'T_Semi-Detached', 'T_other', 'Utilities', 'Rooms', 'Bathrooms',\n",
    "                       'Kitchens', 'Bedrooms', 'Parking', 'Fireplace', 'Feature', 'Pool', 'Interest %',\n",
    "                        'Delta', 'Raw Inflation', 'Population', 'Unemployment']\n",
    "    \n",
    "    return data[feature_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68dbfcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the features from the housing database with crime data features\n",
    "def feature_crime(data):\n",
    "\n",
    "    feature_selected = ['Size', 'T_Detached', 'T_Semi-Detached', 'T_other', 'Utilities', 'Rooms', 'Bathrooms',\n",
    "                       'Kitchens', 'Bedrooms', 'Parking', 'Fireplace', 'Feature', 'Pool', 'crime_density_per_cap',\n",
    "                        'crime_density']\n",
    "    \n",
    "    return data[feature_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a80b5648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the features from the housing database with nearby infrastructure features\n",
    "def feature_infrastructure(data):\n",
    "\n",
    "    feature_selected = ['Size', 'T_Detached', 'T_Semi-Detached', 'T_other', 'Utilities', 'Rooms', 'Bathrooms',\n",
    "                       'Kitchens', 'Bedrooms', 'Parking', 'Fireplace', 'Feature', 'Pool', \n",
    "                        'within_academy', '#_of_academy_within', 'within_education_centres', \n",
    "                        '#_of_education_centres_within', 'within_highschool', '#_of_highschool_within',\n",
    "                        'within_elementary school', '#_of_elementary school_within', 'within_college',\n",
    "                        '#_of_college_within', 'within_learning centre', '#_of_learning centre_within',\n",
    "                        'within_university', '#_of_university_within', 'within_subway_station',\n",
    "                        '#_of_subway_station_within', 'within_cemetery', '#_of_cemetery_within',\n",
    "                        'within_green_space', '#_of_green_space_within']\n",
    "    \n",
    "    return data[feature_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55688bbe",
   "metadata": {},
   "source": [
    "Now, we will see how a random forest regression model performs on this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67355c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200943.76832853354\n",
      "count    3.372600e+04\n",
      "mean     9.941788e+05\n",
      "std      4.825025e+05\n",
      "min      2.675246e+05\n",
      "25%      6.419742e+05\n",
      "50%      8.456701e+05\n",
      "75%      1.201710e+06\n",
      "max      2.999629e+06\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def simple_model(data, features):\n",
    "    # define X and y\n",
    "    X = features(clean_data(data))\n",
    "    y = clean_data(data)['Price'] / clean_data(data)['Cuml Inflation']\n",
    "\n",
    "    # Split into train and val\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, random_state = 42)\n",
    "\n",
    "    # Create model\n",
    "    simple_model = RandomForestRegressor(n_estimators = 100, max_depth = 25, max_features = 0.8, max_samples= 0.9)\n",
    "\n",
    "    # Run Cross validation\n",
    "    rmse = np.median((-cross_val_score(simple_model, X, y, scoring = 'neg_root_mean_squared_error', cv = 5)))\n",
    "    \n",
    "    return rmse, simple_model\n",
    "# print results\n",
    "rmse, simple_model = simple_model(train, feature_engineering) # fit the model on the train data\n",
    "\n",
    "print(rmse)\n",
    " # print out the statistics of the price\n",
    "print((clean_data(train)['Price'] / clean_data(train)['Cuml Inflation']).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f598af2",
   "metadata": {},
   "source": [
    "We get a root mean squared error of about 260,000 dollars. So on average we are 260,000 dollars off for each house. That is much better than the standard deviation (or what a model predicting the average price for each house would get) of 482,000 dollars, but still seems a bit unreliable. For a house worth 2,000,000 dollars, being off by 260,000 dollars would be ok, but if the house is worth 600,000 dollars, our model is not very useful.\n",
    "\n",
    "Lets create a function to bin our data based into different price points (low, medium, or high). We can have one model to predict the price category, and then apply our regression model for each price category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95146df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_data(data):\n",
    "    \"\"\"This function splits data into ['Low', 'Medium', 'High'] price points\"\"\"\n",
    "    \n",
    "    # Split the data into three groups based off their price\n",
    "    quartiles = (data['Price'] / data['Cuml Inflation']).quantile([0.33, 0.71])\n",
    "\n",
    "    # Define the price ranges\n",
    "    bins = [0, quartiles[0.33], quartiles[0.71], float('inf')]\n",
    "    labels = ['Low', 'Medium', 'High']\n",
    "\n",
    "    # Categorize each property\n",
    "    data['Price_Category'] = pd.cut(data['Price'] / data['Cuml Inflation'], bins=bins, labels=labels)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809edf51",
   "metadata": {},
   "source": [
    "Lets run a grid search to look for the best percentile ranges to split our data at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5932edc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.33, 0.71), 0.8021675206704644)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def grid_search_price_splits_adjusted(data, percentile_ranges, random_state=42):\n",
    "    best_accuracy = 0\n",
    "    best_split = None\n",
    "\n",
    "    for percentile_1 in percentile_ranges:\n",
    "        for percentile_2 in percentile_ranges:\n",
    "            if percentile_2 > percentile_1:\n",
    "          # Calculate the quantiles\n",
    "                quartiles = (data['Price'] / data['Cuml Inflation']).quantile([percentile_1, percentile_2])\n",
    "\n",
    "                # Define the price ranges\n",
    "                bins = [0, quartiles[percentile_1], quartiles[percentile_2], float('inf')]\n",
    "                labels = ['Low', 'Medium', 'High']\n",
    "\n",
    "                # Categorize each property\n",
    "                data['Price_Category'] = pd.cut(data['Price'], bins=bins, labels=labels)\n",
    "\n",
    "                # Preprocessing the data\n",
    "                X = feature_engineering(clean_data(data))\n",
    "                y = clean_data(data)['Price_Category']\n",
    "\n",
    "                # Splitting the data\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "                # Training the Random Forest Classifier with class weights\n",
    "                class_weights = 'balanced'\n",
    "                rf_classifier = RandomForestClassifier(random_state=random_state, class_weight=class_weights)\n",
    "                rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "                # Predicting and Evaluating\n",
    "                y_pred = rf_classifier.predict(X_test)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "                conf_matrix = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "\n",
    "                # Calculating category-specific accuracy\n",
    "                accuracy_per_category = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "                \n",
    "                category_accuracy = dict(zip(['Low', 'Medium', 'High'], accuracy_per_category))\n",
    "                \n",
    "                accuracy = np.mean(list(category_accuracy.values()))\n",
    "\n",
    "                # Check if this is the best accuracy\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    best_split = (percentile_1, percentile_2)\n",
    "                    \n",
    "\n",
    "\n",
    "    return best_split, best_accuracy\n",
    "\n",
    "# Example percentile ranges (for demonstration, using a small range)\n",
    "percentile_ranges = [0.30, 0.31, 0.33, 0.34, 0.35, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71]\n",
    "\n",
    "# Assuming 'train_data' is the DataFrame\n",
    "best_split, best_accuracy = grid_search_price_splits_adjusted(train, percentile_ranges)\n",
    "best_split, best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a5f4f0",
   "metadata": {},
   "source": [
    "We also need a function to split our data into X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9700816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, features):\n",
    "    \"\"\"Takes in a data set, filters by features and returns the following parameters:\n",
    "    X_train, X_val, y_train, y_val, X, y, where X are the given values, and y is the target data.\"\"\"\n",
    "    # Splitting the data into features (X) and target (y)\n",
    "    X = features(clean_data(data))\n",
    "\n",
    "    y = clean_data(data)['Price_Category']\n",
    "\n",
    "    # Splitting the data into training and testing sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return (X_train, X_val, y_train, y_val, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a7608",
   "metadata": {},
   "source": [
    "Now we can create a function which will train a random forrest classifier to help determine what price category each house should be in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70624ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_price(data, X_train, y_train, X, features):\n",
    "    \"\"\" This function takes in data, an X_train dataframe, a y_train series, the whole data set of features (X),\n",
    "    and the features. It returns a data set with the predicted Category\"\"\"\n",
    "    # clean the data\n",
    "    data = clean_data(data)\n",
    "    \n",
    "    # Training the Random Forest Classifier with class weights\n",
    "    class_weights = 'balanced'\n",
    "    rf_classifier = RandomForestClassifier(random_state=42, class_weight=class_weights, \n",
    "                                          n_estimators = 50, max_depth = 25, max_features = 0.75, max_samples= 0.75)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf_classifier.predict(features(X))\n",
    "    \n",
    "    # Add predicted classes to the original dataset\n",
    "    data['Category'] = y_pred\n",
    "    return data, rf_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce97a7c",
   "metadata": {},
   "source": [
    "Lets test how the classification is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2af8d5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Low': 0.8595899529599716,\n",
       " 'Medium': 0.8487996306555863,\n",
       " 'High': 0.8763605621895805}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_temp = bin_data(train)\n",
    "X_train, X_val, y_train, y_val, X, y = split_data(train, feature_engineering)\n",
    "temp_data, rf_classifier = (classify_price(train_temp, X_val, y_val, X, feature_engineering))\n",
    "y_pred = temp_data['Category']\n",
    "\n",
    "# Generating the confusion matrix\n",
    "conf_matrix = confusion_matrix(y, y_pred, labels = ['Low', 'Medium', 'High'])\n",
    "\n",
    "# Calculating category-specific accuracy\n",
    "accuracy_per_category = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "\n",
    "# Mapping category names to their accuracies\n",
    "category_accuracy = dict(zip(['Low', 'Medium', 'High'], accuracy_per_category))\n",
    "category_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccee77dc",
   "metadata": {},
   "source": [
    "Not a bad accuracy for dividing up the label, now we can use these labels to train a random forest regression model. First, lets add these predicted categories to the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2613803",
   "metadata": {},
   "source": [
    "Lets do a grid search to find the optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb499359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 10,\n",
       "  'max_features': 0.5,\n",
       "  'max_samples': 0.6,\n",
       "  'n_estimators': 50},\n",
       " -6265624037.2593565)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "def grid_search_rf_params(data, category, param_grid, cv_folds=3):\n",
    "    # Filter the training data for the given category and preprocess\n",
    "    data = bin_data(data)\n",
    "    X_train, X_val, y_train, y_val, X, y = split_data(data, feature_engineering)\n",
    "    data, rf_classifier = classify_price(data, X_train, y_train, X, feature_engineering)\n",
    "    category_data = data[data['Category'] == category]\n",
    "    X_category = feature_engineering(category_data)\n",
    "    y_category = category_data['Price'] / category_data['Cuml Inflation']\n",
    "\n",
    "    # Initialize the GridSearchCV\n",
    "    grid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv=cv_folds, scoring='neg_mean_squared_error', \n",
    "                               return_train_score=True, n_jobs=-1)\n",
    "\n",
    "    # Fit the GridSearchCV\n",
    "    grid_search.fit(X_category, y_category)\n",
    "   \n",
    "\n",
    "    # Best parameters and score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score =grid_search.best_score_  # Convert from negative MSE to positive\n",
    "\n",
    "    return best_params, best_score\n",
    "\n",
    "# Example parameter grid (simplified for demonstration)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [10, 20, 25],\n",
    "    'max_features': [0.5, 0.7, 0.8],\n",
    "    'max_samples': [0.6, 0.9]\n",
    "}\n",
    "\n",
    "# Selecting a category for demonstration (e.g., 'Low')\n",
    "best_params, best_score = grid_search_rf_params(train, 'Low', param_grid)\n",
    "best_params, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124aa16b",
   "metadata": {},
   "source": [
    "Now we can create a function to run our model on all the price categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48a7d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the function to ensure the 'address' column is excluded\n",
    "def train_evaluate_regression_model(data, category, features):\n",
    "    \"\"\"This function takes in data, a category label, and features and predicts the housing prices.\n",
    "    It returns the root mean squared error and the mean error.\"\"\"\n",
    "    # Filter the training data for the given category\n",
    "    category_data = clean_data(data[data['Category'] == category])\n",
    "\n",
    "    # Excluding 'address' and splitting the category data into features and target\n",
    "    X_category = features(clean_data(category_data))\n",
    "    \n",
    "    y_category = category_data['Price'] / category_data['Cuml Inflation']\n",
    "\n",
    "    # Splitting into training and testing sets\n",
    "    X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(X_category,\n",
    "                                                                        y_category, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Training the Linear Regression model\n",
    "    lr_model = RandomForestRegressor(n_estimators = 50, max_depth = 25, max_features = 0.5, max_samples= 0.6)\n",
    "    lr_model.fit(X_train_cat, y_train_cat)\n",
    "\n",
    "    # Predicting and evaluating the model\n",
    "    y_pred_cat = lr_model.predict(X_test_cat)\n",
    "    rmse = np.median(-cross_val_score(lr_model, X_category, y_category, scoring = 'neg_root_mean_squared_error', \n",
    "                            cv = 5))\n",
    "\n",
    "\n",
    "    return rmse, lr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3845c4e8",
   "metadata": {},
   "source": [
    "Now we can create a function to run the entire model for any data and features using the functions we have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e8f287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(data, features):\n",
    "    \"\"\"This function takes in data and a features function and returns the rmse and mae for low, medium, and high\n",
    "    price category houses.\"\"\"\n",
    "    data = bin_data(data) # bin the data\n",
    "    X_train, X_val, y_train, y_val, X, y = split_data(data, features) # split the data\n",
    "    \n",
    "    data, rf_classifier = classify_price(data, X_train, y_train, X, features) # classify the data\n",
    "    \n",
    "    results_v2 = {} # create an empty dictionary\n",
    "    \n",
    "    # this for loop determines the rmse for each price category\n",
    "    for category in ['Low', 'Medium', 'High']:\n",
    "        rmse, lr_model = train_evaluate_regression_model(data, category, features)\n",
    "        results_v2[category] = {'RMSE': rmse}\n",
    "\n",
    "    return results_v2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1572e18",
   "metadata": {},
   "source": [
    "Lets see how our train data performs for all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34e47042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Low': {'RMSE': 66091.42402439148},\n",
       " 'Medium': {'RMSE': 119671.26244230142},\n",
       " 'High': {'RMSE': 282410.9751537141}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model = run_model(train, feature_engineering)\n",
    "train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e84ea4",
   "metadata": {},
   "source": [
    "How does that compare to the standard deviations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c2adde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of Low category: 123581.84618313804\n",
      "Standard Deviation of Medium category: 210809.86592390604\n",
      "Standard Deviation of High category: 624264.3260338929\n"
     ]
    }
   ],
   "source": [
    "standard_dev = [] # create empty list for the standard deviations\n",
    "for category in ['Low', 'Medium', 'High']:\n",
    "    X_train, X_val, y_train, y_val, X, y = split_data(train, feature_engineering) # split the train data\n",
    "    \n",
    "    # categorize the train data\n",
    "    train, rf_classifier = classify_price(train, X_train, y_train, X, feature_engineering)\n",
    "    \n",
    "    category_data = clean_data(train[train['Category'] == category]) # select category data\n",
    "    standard_dev.append(category_data['Price'].std()) # append to standard_dev list\n",
    "    print('Standard Deviation of ' + category + ' category: ' + str(category_data['Price'].std())) # print results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1ceae3",
   "metadata": {},
   "source": [
    "Lets see how our model compares to the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131790da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    percentage = standard_dev[i] / pd.DataFrame(train_model).iloc[0,i]\n",
    "    print(percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713d7252",
   "metadata": {},
   "source": [
    "Now it is time to test our data frame. we will test it for all the features, the house features only, the house features + financial features, the house features + the crime features, and the house features + the infrastructure features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98b73a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_with_test(train_data, test_data, features):\n",
    "    \"\"\"This function takes in train_data, test data and a features function and returns the rmse and mae for low,\n",
    "    medium, and high price category houses for the test data using a random forrest classification model and a \n",
    "    random forrest regression model, trained by the train_data.\"\"\"\n",
    "    train_data = bin_data(train_data) # bin data\n",
    "    X_train, X_val, y_train, y_val, X, y = split_data(train_data, features) # split data\n",
    "    train_data, rf_classifier = classify_price(train_data, X_train, y_train, X, features) # create classification model\n",
    "    \n",
    "    test_data = clean_data(test_data) # clean test data\n",
    "    \n",
    "    X_test = features(test_data) # create X_test\n",
    "    y_test = test_data['Price'] / test_data['Cuml Inflation'] # create y_test\n",
    "    \n",
    "    test_data['Category'] = rf_classifier.predict(X_test) # predict categories for test data\n",
    "    \n",
    "    \n",
    "    results_v2 = {}\n",
    "    for category in ['Low', 'Medium', 'High']:\n",
    "        rmse, lr_model = train_evaluate_regression_model(train_data, category, features) # train regression model\n",
    "        \n",
    "        X_test_cat = X_test[test_data['Category'] == category] # create X test data for the category\n",
    "        y_test_cat = y_test[test_data['Category'] == category] # create y test data for the category\n",
    "        \n",
    "        y_pred = lr_model.predict(X_test_cat) # predict prices\n",
    "        rmse_test = (mean_squared_error(y_test_cat, y_pred, squared=False)) # calculate mean squared error\n",
    "        results_v2[category] = {'RMSE': rmse_test} # append to results\n",
    "\n",
    "    return results_v2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6094e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Low': {'RMSE': 84541.08928088963},\n",
       " 'Medium': {'RMSE': 173707.18892776125},\n",
       " 'High': {'RMSE': 323044.3866781776}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = run_model_with_test(train, test, feature_engineering)\n",
    "test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfa5b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_houses = run_model_with_test(train, test, feature_houses)\n",
    "test_model_houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9929ed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_financial = run_model_with_test(train, test, feature_financial)\n",
    "test_model_financial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4ab66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_crime = run_model_with_test(train, test, feature_crime)\n",
    "test_model_crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d04d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_infrastructure = run_model_with_test(train, test, feature_infrastructure)\n",
    "test_model_infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c03bc7",
   "metadata": {},
   "source": [
    "Lets summarize our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9ccaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.concat([pd.DataFrame(test_model), pd.DataFrame(test_model_houses),\n",
    "                        pd.DataFrame(test_model_financial), pd.DataFrame(test_model_crime),\n",
    "                        pd.DataFrame(test_model_infrastructure)])\n",
    "\n",
    "test_results = test_results.reset_index(drop = True)\n",
    "test_results = test_results.rename(index={0: \"Full Model\", 1: \"Houses Model\", 2: \"Financial Model\", \n",
    "                                         3: \"Crime Model\", 4: 'Infrastructure Model'})\n",
    "test_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca81b4e",
   "metadata": {},
   "source": [
    "Now we can make a vizualization to compare how different models influnced the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0c320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_axis = np.arange(len(test_results)) # create x-axis length array\n",
    "\n",
    "Low = list(test_results['Low']) # create low price array\n",
    "Med = list(test_results['Medium']) # create medium price array\n",
    "High = list(test_results['High']) # create high price array\n",
    "  \n",
    "plt.bar(X_axis - 0.2, Low, 0.2, label = 'Low') \n",
    "plt.bar(X_axis, Med, 0.2, label = 'Medium') \n",
    "plt.bar(X_axis + 0.2, High, 0.2, label = 'High') \n",
    "\n",
    "plt.xticks(X_axis, test_results.index, rotation=25)\n",
    "plt.xlabel(\"Models\") \n",
    "plt.ylabel(\"Root Mean Squared Errors\") \n",
    "plt.title(\"Root Mean Squared Errors for Each Model\") \n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b997cf",
   "metadata": {},
   "source": [
    "Nice, our full model is performing the best! It seems like the infrastructure has a large influence, while the crime data and financial data on its own does not seem to help our model much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf03eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
